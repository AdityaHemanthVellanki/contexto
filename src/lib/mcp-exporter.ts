import { generateUploadUrl, generateFileKey } from '@/lib/r2-client';
import { getFirestore } from '@/lib/firebase-admin';
import { v4 as uuidv4 } from 'uuid';
import * as fs from 'fs';
import * as path from 'path';
import * as os from 'os';
import archiver from 'archiver';

interface PipelineData {
  id: string;
  userId: string;
  metadata: {
    fileName: string;
    purpose: string;
    vectorStore: string;
    chunksCount: number;
    chunkSize: number;
    overlap: number;
  };
  config: {
    embedding: {
      model: string;
      provider: string;
    };
    indexing: {
      backend: string;
    };
    retrieval: {
      topK: number;
      searchType: string;
    };
  };
}

/**
 * Generate MCP server package.json
 */
function generatePackageJson(pipelineId: string): string {
  return JSON.stringify({
    name: `mcp-pipeline-${pipelineId}`,
    version: '1.0.0',
    description: 'MCP Server generated by Contexto',
    main: 'server.js',
    scripts: {
      start: 'node server.js',
      dev: 'node server.js'
    },
    dependencies: {
      '@modelcontextprotocol/sdk': '^0.4.0',
      'dotenv': '^16.0.0'
    },
    engines: {
      node: '>=18.0.0'
    }
  }, null, 2);
}

/**
 * Generate MCP server.js file
 */
function generateServerJs(pipeline: PipelineData): string {
  return `#!/usr/bin/env node

const { Server } = require('@modelcontextprotocol/sdk/server/index.js');
const { StdioServerTransport } = require('@modelcontextprotocol/sdk/server/stdio.js');
const { CallToolRequestSchema, ListToolsRequestSchema } = require('@modelcontextprotocol/sdk/types.js');

// Load environment variables
require('dotenv').config();

const server = new Server({
  name: 'contexto-pipeline-${pipeline.id}',
  version: '1.0.0',
  description: 'RAG pipeline for ${pipeline.metadata.purpose}'
}, {4
  capabilities: {
    tools: {}
  }
});

// Tool definitions
server.setRequestHandler(ListToolsRequestSchema, async () => {
  return {
    tools: [
      {
        name: 'search_knowledge',
        description: 'Search the knowledge base for relevant information',
        inputSchema: {
          type: 'object',
          properties: {
            query: {
              type: 'string',
              description: 'The search query'
            },
            limit: {
              type: 'number',
              description: 'Maximum number of results to return',
              default: ${pipeline.config.retrieval.topK}
            }
          },
          required: ['query']
        }
      },
      {
        name: 'get_pipeline_info',
        description: 'Get information about this pipeline',
        inputSchema: {
          type: 'object',
          properties: {}
        }
      }
    ]
  };
});

// Tool handlers
server.setRequestHandler(CallToolRequestSchema, async (request) => {
  const { name, arguments: args } = request.params;
  
  switch (name) {
    case 'search_knowledge':
      return await searchKnowledge(args.query, args.limit || ${pipeline.config.retrieval.topK});
    
    case 'get_pipeline_info':
      return {
        content: [
          {
            type: 'text',
            text: JSON.stringify({
              pipelineId: '${pipeline.id}',
              purpose: '${pipeline.metadata.purpose}',
              vectorStore: '${pipeline.metadata.vectorStore}',
              chunksCount: ${pipeline.metadata.chunksCount},
              chunkSize: ${pipeline.metadata.chunkSize},
              overlap: ${pipeline.metadata.overlap},
              retrievalConfig: {
                topK: ${pipeline.config.retrieval.topK},
                searchType: '${pipeline.config.retrieval.searchType}'
              }
            }, null, 2)
          }
        ]
      };
    
    default:
      throw new Error(\`Unknown tool: \${name}\`);
  }
});

// Search function implementation
async function searchKnowledge(query, limit = ${pipeline.config.retrieval.topK}) {
  try {
    // This would integrate with your vector store
    // For now, return a placeholder response
    return {
      content: [
        {
          type: 'text',
          text: \`Search results for: "\${query}"\n\nThis MCP server is configured to search ${pipeline.metadata.chunksCount} chunks from "${pipeline.metadata.fileName}".\n\nTo enable actual search functionality, configure the following environment variables:\n- AZURE_OPENAI_API_KEY\n- AZURE_OPENAI_ENDPOINT\n- PINECONE_API_KEY\n- PINECONE_ENVIRONMENT\`
        }
      ]
    };
  } catch (error) {
    return {
      content: [
        {
          type: 'text',
          text: \`Error searching knowledge base: \${error.message}\`
        }
      ]
    };
  }
}

// Start the server
async function main() {
  const transport = new StdioServerTransport();
  await server.connect(transport);
  console.error('MCP Server started for pipeline ${pipeline.id}');
}

if (require.main === module) {
  main().catch(console.error);
}
`;
}

/**
 * Generate .env.example file
 */
function generateEnvExample(): string {
  return `# Azure OpenAI Configuration
AZURE_OPENAI_API_KEY=your_azure_openai_api_key
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_DEPLOYMENT_EMBEDDING=text-embedding-ada-002
AZURE_OPENAI_DEPLOYMENT_TURBO=gpt-35-turbo

# Pinecone Configuration
PINECONE_API_KEY=your_pinecone_api_key
PINECONE_ENVIRONMENT=your_pinecone_environment

# Cloudflare R2 Configuration (if using R2 for file storage)
CF_R2_ACCESS_KEY_ID=your_r2_access_key
CF_R2_SECRET_ACCESS_KEY=your_r2_secret_key
CF_R2_BUCKET_NAME=your_bucket_name
CF_R2_ENDPOINT=https://your-account-id.r2.cloudflarestorage.com
`;
}

/**
 * Generate README.md file
 */
function generateReadme(pipeline: PipelineData): string {
  return `# MCP Pipeline: ${pipeline.metadata.purpose}

This is an MCP (Model Context Protocol) server generated by Contexto for the pipeline "${pipeline.metadata.purpose}".

## Overview

- **Pipeline ID**: ${pipeline.id}
- **Source File**: ${pipeline.metadata.fileName}
- **Vector Store**: ${pipeline.metadata.vectorStore}
- **Chunks**: ${pipeline.metadata.chunksCount}
- **Chunk Size**: ${pipeline.metadata.chunkSize} characters
- **Overlap**: ${pipeline.metadata.overlap} characters

## Installation

1. Install dependencies:
   \`\`\`bash
   npm install
   \`\`\`

2. Copy \`.env.example\` to \`.env\` and configure your API keys:
   \`\`\`bash
   cp .env.example .env
   \`\`\`

3. Start the server:
   \`\`\`bash
   npm start
   \`\`\`

## Available Tools

### search_knowledge
Search the knowledge base for relevant information.

**Parameters:**
- \`query\` (string, required): The search query
- \`limit\` (number, optional): Maximum number of results (default: ${pipeline.config.retrieval.topK})

### get_pipeline_info
Get information about this pipeline configuration.

## Configuration

This MCP server requires the following environment variables:

- \`AZURE_OPENAI_API_KEY\`: Your Azure OpenAI API key
- \`AZURE_OPENAI_ENDPOINT\`: Your Azure OpenAI endpoint
- \`PINECONE_API_KEY\`: Your Pinecone API key
- \`PINECONE_ENVIRONMENT\`: Your Pinecone environment

## Generated by Contexto

This MCP server was automatically generated by [Contexto](https://contexto.dev) on ${new Date().toISOString()}.
`;
}

/**
 * Create a ZIP archive from a directory
 */
async function createZipArchive(sourceDir: string, outputPath: string): Promise<void> {
  return new Promise((resolve, reject) => {
    const output = fs.createWriteStream(outputPath);
    const archive = archiver('zip', { zlib: { level: 9 } });

    output.on('close', () => {
      console.log(`Archive created: ${archive.pointer()} total bytes`);
      resolve();
    });

    archive.on('error', (err: any) => {
      reject(err);
    });

    archive.pipe(output);
    archive.directory(sourceDir, false);
    archive.finalize();
  });
}

/**
 * Export MCP pipeline bundle to R2 storage
 */
export async function exportMCPBundle(pipelineId: string, userId: string): Promise<{
  exportId: string;
  downloadUrl: string;
  r2Key: string;
}> {
  try {
    // Fetch pipeline data from Firestore
    const db = await getFirestore();
    const pipelineDoc = await db.collection('pipelines').doc(pipelineId).get();
    
    if (!pipelineDoc.exists) {
      throw new Error('Pipeline not found');
    }
    
    const pipelineData = pipelineDoc.data() as PipelineData;
    
    // Create temporary directory for MCP files
    const tempDir = path.join(os.tmpdir(), `mcp-export-${pipelineId}-${Date.now()}`);
    await fs.promises.mkdir(tempDir, { recursive: true });
    
    try {
      // Generate MCP server files
      await fs.promises.writeFile(
        path.join(tempDir, 'package.json'),
        generatePackageJson(pipelineId)
      );
      
      await fs.promises.writeFile(
        path.join(tempDir, 'server.js'),
        generateServerJs(pipelineData)
      );
      
      await fs.promises.writeFile(
        path.join(tempDir, '.env.example'),
        generateEnvExample()
      );
      
      await fs.promises.writeFile(
        path.join(tempDir, 'README.md'),
        generateReadme(pipelineData)
      );
      
      // Create ZIP archive
      const zipPath = path.join(tempDir, 'mcp-pipeline.zip');
      await createZipArchive(tempDir, zipPath);
      
      // Upload to R2
      const exportId = uuidv4();
      const r2Key = `users/${userId}/exports/${exportId}/mcp-pipeline.zip`;
      const uploadUrl = await generateUploadUrl(r2Key, 'application/zip');
      
      // Read ZIP file and upload
      const zipBuffer = await fs.promises.readFile(zipPath);
      const uploadResponse = await fetch(uploadUrl, {
        method: 'PUT',
        body: zipBuffer,
        headers: {
          'Content-Type': 'application/zip',
          'Content-Length': zipBuffer.length.toString()
        }
      });
      
      if (!uploadResponse.ok) {
        throw new Error(`Failed to upload MCP bundle: ${uploadResponse.statusText}`);
      }
      
      // Store export metadata in Firestore
      const exportMetadata = {
        id: exportId,
        pipelineId,
        userId,
        r2Key,
        fileName: 'mcp-pipeline.zip',
        fileSize: zipBuffer.length,
        createdAt: new Date(),
        status: 'completed'
      };
      
      await db.collection('exports').doc(exportId).set(exportMetadata);
      
      // Generate download URL (this will be publicly accessible)
      const downloadUrl = `https://${process.env.CF_R2_BUCKET_NAME}.r2.dev/${r2Key}`;
      
      return {
        exportId,
        downloadUrl,
        r2Key
      };
      
    } finally {
      // Clean up temporary directory
      await fs.promises.rm(tempDir, { recursive: true, force: true });
    }
    
  } catch (error) {
    console.error('MCP export error:', error);
    const errorMessage = error instanceof Error ? error.message : String(error);
    throw new Error(`Failed to export MCP bundle: ${errorMessage}`);
  }
}
